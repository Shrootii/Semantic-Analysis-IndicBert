{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImW5xLg5Ezyo"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/transformers/v3.2.0/custom_datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5ceeO9LhWkU"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HNUE5fXIb-W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCHVN0B51nMe"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLuKyvHJ47xK",
        "outputId": "62f238fd-9385-4169-a10e-0acc59f2eb73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  ‡§≤‡•ã‡§ó ‡§µ‡§§‡§® ‡§§‡§ï ‡§ñ‡§æ ‡§ú‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§á‡§∏‡§ï‡§æ ‡§á‡§∏‡•á ‡§Ø‡§ï‡•Ä‡§® ‡§®‡§π‡•Ä‡§Ç‡§Æ‡§æ‡§® ‡§ú...      1\n",
            "1  ‡§ó‡•Å‡§Æ‡§®‡§æ‡§Æ ‡§π‡•à ‡§µ‡§§‡§® ‡§™‡§∞ ‡§Æ‡§ø‡§ü‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§≤‡•ã‡§ó ‡§Ü‡§§‡§®‡•ç‡§ï‡§µ‡§æ‡§¶‡§ø‡§Ø‡•ã‡§Ç ‡§∏...      1\n",
            "2  ‡§ú‡§º‡§Ç‡§ú‡•Ä‡§∞ ‡§¨‡§¶‡§≤‡•Ä ‡§ú‡§æ ‡§∞‡§π‡•Ä ‡§•‡•Ä ‡§Æ‡•à‡§Ç ‡§∏‡§Æ‡§ù‡§æ ‡§•‡§æ ‡§∞‡§ø‡§π‡§æ‡§à ‡§π‡•ã ‡§ó‡§Ø‡•Ä ‡§π‡•à      1\n",
            "3  ‡§Ø‡•Ç‡§™‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§°‡§º‡•á ‡§∏‡•ç‡§§‡§∞ ‡§™‡§∞ ‡§¶‡§Ç‡§ó‡•á ‡§ï‡§∞‡§µ‡§æ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à ‡§¨‡•Ä‡§ú‡•á‡§™‡•Ä...      1\n",
            "4  ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§§‡•Ä ‡§π‡•à ‡§á‡§∏‡§≤‡§ø‡§è ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä ‡§ü‡•ç‡§µ‡§ø‡§ü ‡§ú‡•ç‡§Ø‡§æ‡§¶‡§æ...      1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# file_path = \"hindi.csv\"\n",
        "# df = pd.read_csv(file_path)\n",
        "\n",
        "# # Map label names to integers\n",
        "# label_map = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
        "# df['label'] = df['label'].apply(lambda x: label_map[x])\n",
        "# print(df.head())\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"hindi.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Map label names to integers\n",
        "label_map = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
        "\n",
        "# Update the lambda function to handle NaN values\n",
        "df['label'] = df['label'].apply(lambda x: label_map.get(x, -1) if pd.notna(x) else x)\n",
        "print(df.head())\n",
        "\n",
        "# import pandas as pd\n",
        "\n",
        "# # Define the file paths\n",
        "# file_paths = [\"tamil_train.tsv\"]\n",
        "\n",
        "# # Map label names to integers\n",
        "# label_map = {\"Positive\": 0, \"Negative\": 1, \"Mixed_feelings\": 2, \"unknown_state\": 3, \"not-Tamil\": 4}\n",
        "\n",
        "# # Read data from each file and concatenate\n",
        "# dfs = []\n",
        "# for file_path in file_paths:\n",
        "#     # Read data\n",
        "#     df = pd.read_csv(file_path, delimiter='\\t')\n",
        "\n",
        "#     # Map labels\n",
        "#     df['category'] = df['category'].apply(lambda x: x.strip())  # Remove leading/trailing whitespaces\n",
        "#     df['category'] = df['category'].apply(lambda x: label_map.get(x, -1))  # Map labels\n",
        "\n",
        "#     dfs.append(df)\n",
        "\n",
        "# # Concatenate dataframes\n",
        "# combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# print(combined_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn7OlLJnwZJH"
      },
      "outputs": [],
      "source": [
        "# data.to_csv(\"/content/drive/MyDrive/Youtube Tutorials/datasets/toxic_commnets.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dbrirLG5D0A",
        "outputId": "f479f08e-5512-4f35-a6c4-4a28c5c6c58a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text\n",
              "‡§∏‡§∏‡•Å‡§∞ ‡§®‡•á ‡§ï‡§ø‡§Ø‡§æ ‡§¨‡§≤‡§æ‡§§‡•ç‡§ï‡§æ‡§∞ ISLAMIC LAW-NOW WIFE IS MOTHER ‡§á‡§∏‡•ç‡§≤‡§æ‡§Æ‡§ø‡§ï ‡§ï‡§º‡§æ‡§®‡•Ç‡§®-‡§Ö‡§¨ ‡§¨‡•Ä‡§µ‡•Ä ‡§ï‡•ã ‡§Æ‡§æ‡§Å ‡§Æ‡§æ‡§®‡•ã                                                                8\n",
              "‡§ú‡§Æ‡•ç‡§Æ‡•Ç-‡§ï‡§∂‡•ç‡§Æ‡•Ä‡§∞ ‡§¨‡§æ‡§¢‡§º : PM ‡§®‡•á ‡§≤‡§ø‡§Ø‡§æ ‡§π‡§æ‡§≤‡§æ‡§§ ‡§ï‡§æ ‡§ú‡§æ‡§Ø‡§ú‡§æ 1000 ‡§ï‡§∞‡•ã‡§°‡§º ‡§∞‡•Å‡§™‡§è ‡§ï‡•Ä ‡§¶‡•Ä ‡§Ü‡§∞‡•ç‡§•‡§ø‡§ï ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ - Zee News ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä                                                     7\n",
              "‡§®‡§ø‡§∞‡•ç‡§¶‡•ã‡§∑ Asaram Bapu Ji ‡§ï‡•ã POCSO ‡§ï‡•á ‡§ó‡§≤‡§§ ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§∏‡•á ‡§´‡§Å‡§∏‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ| Why Jodhpur Police let #365DaysOfPOCSOmisuse happen?                                     4\n",
              "J&K: ‡§≠‡•Ç‡§∏‡•ç‡§ñ‡§≤‡§® ‡§Æ‡•á‡§Ç 7 ‡§ï‡•Ä ‡§Æ‡•å‡§§ 20 ‡§≤‡§æ‡§™‡§§‡§æ: ‡§ú‡§Æ‡•ç‡§Æ‡•Ç-‡§ï‡§∂‡•ç‡§Æ‡•Ä‡§∞ ‡§ï‡•á ‡§â‡§ß‡§Æ‡§™‡•Å‡§∞ ‡§ú‡§ø‡§≤‡•á ‡§ï‡•á ‡§è‡§ï ‡§∏‡•Å‡§¶‡•Ç‡§∞ ‡§™‡§∞‡•ç‡§µ‡§§‡•Ä‡§Ø ‡§ó‡§æ‡§Ç‡§µ ‡§Æ‡•á‡§Ç ‡§≠‡§æ‡§∞‡•Ä ‡§¨‡§æ‡§∞‡§ø‡§∂ ‡§ï‡•á ‡§¨‡§æ                                           3\n",
              "RT @theworldindex: World most polluted cities 2018:\\n\\n1.üáÆüá≥ Gurugram\\n2.üáÆüá≥ Ghaziabad\\n3.üáµüá∞ Faisalabad\\n4.üáÆüá≥ Faridabad\\n5.üáÆüá≥ Bhiwadi\\n6.üáÆüá≥ Noida\\n7.‚Ä¶    3\n",
              "                                                                                                                                                       ..\n",
              "@vikasbha @narendramodi Kya baat... Suri... Chhaa gya... Hero hai ladka :-)                                                                             1\n",
              "@ashu3page @IndiaToday ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§ú‡•Ä‡§µ‡§® ‡§ï‡§æ ‡§®‡§ø‡§Ø‡§Æ ‡§π‡•à :)                                                                                                      1\n",
              "@nehabatham03 hahaha ü§£ü§£ü§£ü§£ ‡§ï‡§π‡§æ‡§®‡•Ä ‡§ò‡§∞-‡§ò‡§∞ ‡§ï‡•Ä                                                                                                                1\n",
              "@iamShashizanje Sympathy nahin sahab garv hai                                                                                                           1\n",
              "‡§Ø‡•ã‡§ó ‡§∏‡•á ‡§Ö‡§≤‡§ó‡§æ‡§µ‡§µ‡§æ‡§¶‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§Ü‡§§‡§Ç‡§ï ‡§ï‡•Ä ‡§´‡§Ç‡§°‡§ø‡§Ç‡§ó ‡§™‡§∞ ‡§∂‡•Ä‡§∞‡•ç‡§∑‡§∂‡§æ‡§∑‡§® ‡§ï‡§∞‡§æ‡§è‡§ó‡§æ NIA‡•§ https://t.co/K4nbuOS0vP                                                                  1\n",
              "Name: count, Length: 1878, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df['text'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2HyJRvG5trP"
      },
      "outputs": [],
      "source": [
        "data = df[['text','label']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR2qvtcuTHMa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s32nl2kn56cH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1JlB3eYiV8a",
        "outputId": "0c74f080-450c-46d1-dbff-70a6b3d96867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# from transformers import BertTokenizer, BertForSequenceClassification\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n",
        "\n",
        "X = tokenizer(df['text'].tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "1fe1b832ed3c4c11b5e17f3ae093151c",
            "ce3dd38c2ad2459abfc82aa5d51a7b8d",
            "0c27b67b98534b3aaa055c101fc157e5",
            "734f36d2b996443c90e79624b33664ae",
            "35f05b4096894af3a9567f3bdd0931b8",
            "811fd6fc70474ab2b57b6e641d8c6d65",
            "0093232fc5ec462c829d5846f698daee",
            "4032b92b72c345eaad6a24a2e45bcec2",
            "b1f10623bf6a4b3283ee74545f5e84ea",
            "a0e7a56fff15412b88432daeb4894d17",
            "7b9bbf4e1e4c4a71843c973e678103dc"
          ]
        },
        "id": "WPKswImmYUjO",
        "outputId": "676b8537-2096-4b6a-87d6-7fedfffc5251"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/135M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fe1b832ed3c4c11b5e17f3ae093151c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained('ai4bharat/indic-bert', num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tESWTOfVHEqA",
        "outputId": "28fd77d5-007e-4475-9c4e-9034dcb99ba8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[2, 7922, 472, 43931, 3, 0], [2, 7922, 472, 8408, 8, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1]]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "sample_data = [\"I am eating\",\"I am playing \"]\n",
        "tokenizer(sample_data, padding=True, truncation=True, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyWcZBQuid2V"
      },
      "outputs": [],
      "source": [
        "X = list(df[\"text\"])\n",
        "y = list(df[\"label\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll_YffE1rrKV",
        "outputId": "4e1bbb1c-d1c5-43b4-e897-63a615207bb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_train_tokenized.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA1ZDp4SqPNN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_1BwDTtc3FrS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5TGibGZIAZT",
        "outputId": "4cbec86f-2832-4f28-e014-670418fcc7b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "print(X_train_tokenized['attention_mask'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2bs25fZish6",
        "outputId": "62ca4d45-4362-4ce9-822f-82519bf8e243"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1534, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(X_train),len(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Dq__AdmjiEh"
      },
      "outputs": [],
      "source": [
        "# Create torch dataset\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52bjWWitkMRw"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset(X_train_tokenized, y_train)\n",
        "val_dataset = Dataset(X_val_tokenized, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvU9P6xhsgLL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqrFeE7Trgtd",
        "outputId": "8c7effd6-789f-4ba5-8f75-1ca07c676609"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([     2,  48856,     98,  93897,     32,  31178,     21, 100597,   2323,\n",
              "           5211,   1682,      8, 144354,  35162, 100478,  33892,  73559,     21,\n",
              "             33,  32224,    686,  94675,  19054,  10529,    580,      9,   8217,\n",
              "          50584,   2864,   2805, 132443,   1661,   3343,   2805,     32,  19078,\n",
              "           2611,  15746, 117100,      3,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0,      0]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor(0)}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "train_dataset[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSYfH_aIkOwf"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p):\n",
        "    print(type(p))\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred)\n",
        "    precision = precision_score(y_true=labels, y_pred=pred)\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vFcXgFFNkRDP",
        "outputId": "d2f6d278-b77a-479e-896b-0cdddf5c2237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='384' max='384' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [384/384 00:36, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.100900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.104300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.099400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.098600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.100700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.096000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.102200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.099800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.096800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.090300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.059700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.080900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.984700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.972500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.856400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.795500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.681800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.860700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.804400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.842600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.859400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.839400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.855700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.713900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.859800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.815700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.609800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.770400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.738600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.875200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.694000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.622100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.703900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.667600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.569500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=384, training_loss=0.8965181472400824, metrics={'train_runtime': 38.3023, 'train_samples_per_second': 80.1, 'train_steps_per_second': 10.025, 'total_flos': 9309044055480.0, 'train_loss': 0.8965181472400824, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# # Define Trainer\n",
        "# args = TrainingArguments(\n",
        "#     output_dir=\"output\",\n",
        "#     num_train_epochs=1,\n",
        "#     per_device_train_batch_size=8\n",
        "\n",
        "# )\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=8,  # batch size per device during training\n",
        "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics # evaluation dataset\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_6YDA1IxUUkp",
        "outputId": "ba2f36c1-f46d-4dc4-c4de-0a37e5fd25bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/297.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m204.8/297.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.29.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.39.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "28b7987c5e954edb9128ba78fb6ca0cc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install -U accelerate\n",
        "! pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQvy4NALUUnf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJeSaHPhngCV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "Ia14Y_UmN7qM",
        "outputId": "c812dc94-2771-4414-b6e9-e6fe6c35a1ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [114/114 00:07]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'transformers.trainer_utils.EvalPrediction'>\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-f245b31d31e3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3364\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3365\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3366\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3367\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3654\u001b[0m                 )\n\u001b[1;32m   3655\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3656\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3657\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3658\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-49567de0a237>\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   2096\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m     \"\"\"\n\u001b[0;32m-> 2098\u001b[0;31m     _, r, _, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[1;32m   2099\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1389\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1392\u001b[0m                 \u001b[0;34m\"Target is %s but average='binary'. Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                 \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
          ]
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2Ec_YcJUTcn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX1xAXjhqibr"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdVqrPN0kVLY",
        "outputId": "a77f561f-1429-4f17-f4f2-0349c478b871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.7745,  1.6292, -2.4814]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "tensor([[0.2950, 0.6936, 0.0114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29503676, 0.6935903 , 0.01137299]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "text = \"‡§ó‡•Å‡§Æ‡§®‡§æ‡§Æ ‡§π‡•à ‡§µ‡§§‡§® ‡§™‡§∞ ‡§Æ‡§ø‡§ü‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§≤‡•ã‡§ó ‡§Ü‡§§‡§®‡•ç‡§ï‡§µ‡§æ‡§¶‡§ø‡§Ø‡•ã‡§Ç ‡§∏‡•á ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§Æ‡§∂‡§π‡•Ç‡§∞ ‡§π‡•ã ‡§ó‡§Ø‡•á\"\n",
        "# text = \"go to hell\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model(**inputs)\n",
        "print(outputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zGTQP62MbAr"
      },
      "outputs": [],
      "source": [
        "trainer.save_model('CustomModel2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLnznjr1PYVG"
      },
      "outputs": [],
      "source": [
        "# trainer.save_model('/content/drive/MyDrive/Youtube Tutorials/toxic')\n",
        "# model_2 = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/Youtube Tutorials/toxic\")\n",
        "# model_2.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTu-SoK6MeVJ",
        "outputId": "4190eaaa-898e-48d4-b362-4e60632b38c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlbertForSequenceClassification(\n",
              "  (albert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (attention_dropout): Dropout(p=0, inplace=False)\n",
              "                (output_dropout): Dropout(p=0, inplace=False)\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "              (dropout): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (pooler_activation): Tanh()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\n",
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# model_2 = AutoModelForSequenceClassification.from_pretrained(\"fine_tuning\")\n",
        "# model_2.to('cuda')\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_2 = AutoModelForSequenceClassification.from_pretrained(\"CustomModel2\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Move the model to the appropriate device (e.g., GPU if available)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_2.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8dqYXZwM12Z",
        "outputId": "99ecf2f9-7475-4c1f-b0cb-d3894ded5b2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2869163 , 0.69707155, 0.01601219]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# text = \"That was good point\"\n",
        "text = \"‡§≤‡•ã‡§ó ‡§µ‡§§‡§® ‡§§‡§ï ‡§ñ‡§æ ‡§ú‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§á‡§∏‡§ï‡§æ ‡§á‡§∏‡•á ‡§Ø‡§ï‡•Ä‡§® ‡§®‡§π‡•Ä‡§Ç‡§Æ‡§æ‡§® ‡§ú‡§æ‡§è‡§ó‡§æ ‡§§‡•Ç ‡§≤‡•á ‡§ú‡§æ‡§ï‡§∞ ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§á‡§∏‡•á ‡§¶‡§ø‡§ñ‡§æ ‡§≤‡§æ ‡§¶‡•ã‡§∏‡•ç‡§§\"\n",
        "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n",
        "outputs = model_2(**inputs)\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predictions = predictions.cpu().detach().numpy()\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owBTtpMkPm0l"
      },
      "outputs": [],
      "source": [
        "#CustomModel Output-\n",
        "array([[0.2257416 , 0.7594996 , 0.01475879]], dtype=float32)\n",
        "# CustomModel2 Output-\n",
        "array([[0.14694382, 0.8465548 , 0.00650142]], dtype=float32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmJcT0fNZwOW",
        "outputId": "49f6f6b8-bac8-42d4-d266-1e91a1dd6509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZXlHxZAZwak"
      },
      "outputs": [],
      "source": [
        "\n",
        "#EVALUATING MODEL\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"hindi sentiment analysis.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df = df.dropna()\n",
        "\n",
        "# Map label names to integers\n",
        "label_map = {\"positive\": 0, \"negative\": 1, \"neutral\": 2}\n",
        "\n",
        "# Update the lambda function to handle NaN values\n",
        "df['label'] = df['label'].apply(lambda x: label_map.get(x, -1) if pd.notna(x) else x)\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n",
        "model_2 = AutoModelForSequenceClassification.from_pretrained(\"fine_tuned_model\")\n",
        "\n",
        "# Move the model to the appropriate device (e.g., GPU if available)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_2.to(device)\n",
        "\n",
        "# Load your evaluation dataset\n",
        "# Assuming you have X_eval as input texts and y_eval as corresponding labels\n",
        "\n",
        "\n",
        "\n",
        "X = tokenizer(df['text'].tolist(), padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
        "X = list(df[\"text\"])\n",
        "y = list(df[\"label\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
        "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
        "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
        "\n",
        "# Tokenize the evaluation dataset\n",
        "eval_inputs = tokenizer(X_val, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Move inputs to the appropriate device\n",
        "eval_inputs = {key: val.to(device) for key, val in eval_inputs.items()}\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    outputs = model_2(**eval_inputs)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "# Convert probabilities to predicted labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_val, predicted_labels)\n",
        "recall = recall_score(y_val, predicted_labels, average='weighted')\n",
        "precision = precision_score(y_val, predicted_labels, average='weighted')\n",
        "f1 = f1_score(y_val, predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1-score:\", f1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fe1b832ed3c4c11b5e17f3ae093151c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce3dd38c2ad2459abfc82aa5d51a7b8d",
              "IPY_MODEL_0c27b67b98534b3aaa055c101fc157e5",
              "IPY_MODEL_734f36d2b996443c90e79624b33664ae"
            ],
            "layout": "IPY_MODEL_35f05b4096894af3a9567f3bdd0931b8"
          }
        },
        "ce3dd38c2ad2459abfc82aa5d51a7b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_811fd6fc70474ab2b57b6e641d8c6d65",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0093232fc5ec462c829d5846f698daee",
            "value": "pytorch_model.bin:‚Äá100%"
          }
        },
        "0c27b67b98534b3aaa055c101fc157e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4032b92b72c345eaad6a24a2e45bcec2",
            "max": 134982446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1f10623bf6a4b3283ee74545f5e84ea",
            "value": 134982446
          }
        },
        "734f36d2b996443c90e79624b33664ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e7a56fff15412b88432daeb4894d17",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7b9bbf4e1e4c4a71843c973e678103dc",
            "value": "‚Äá135M/135M‚Äá[00:01&lt;00:00,‚Äá122MB/s]"
          }
        },
        "35f05b4096894af3a9567f3bdd0931b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "811fd6fc70474ab2b57b6e641d8c6d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0093232fc5ec462c829d5846f698daee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4032b92b72c345eaad6a24a2e45bcec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1f10623bf6a4b3283ee74545f5e84ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0e7a56fff15412b88432daeb4894d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9bbf4e1e4c4a71843c973e678103dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}